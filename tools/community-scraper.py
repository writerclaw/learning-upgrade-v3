#!/usr/bin/env python3
"""
Community Scraper - OpenClaw ç¤¾åŒºå†…å®¹æŠ“å–
åŠŸèƒ½ï¼š
1. æŠ“å– awesome-openclaw ç¤¾åŒºèµ„æº
2. ç›‘æ§ ClawHub æŠ€èƒ½åŠ¨æ€
3. è¿½è¸ªæŠ€æœ¯ç¤¾åŒºè®¨è®ºï¼ˆHacker News ç­‰ï¼‰
4. ç”Ÿæˆç¤¾åŒºè¶‹åŠ¿æŠ¥å‘Š

å®‰å…¨ï¼š
- ä»ç¯å¢ƒå˜é‡è¯»å–å¯†é’¥
- å¤–éƒ¨å†…å®¹ä»…ä½œä¸ºæ•°æ®å¤„ç†
- è¶…æ—¶é™åˆ¶é˜²æ­¢ hangs
"""

import urllib.request
import json
import ssl
import os
import re
from datetime import datetime
from pathlib import Path

# ==================== å®‰å…¨æœºåˆ¶ ====================

def detect_injection(content: str) -> bool:
    """æ£€æµ‹æ½œåœ¨çš„æç¤ºè¯æ³¨å…¥æ¨¡å¼"""
    patterns = [
        r"ignore\s+previous\s+instructions",
        r"disregard\s+all",
        r"you\s+are\s+now",
        r"bypass\s+safety",
    ]
    lower_content = content.lower()
    for pattern in patterns:
        if re.search(pattern, lower_content):
            print(f"âš ï¸  æ£€æµ‹åˆ°æ½œåœ¨çš„æç¤ºè¯æ³¨å…¥æ¨¡å¼")
            return True
    return False

# é…ç½®
# ä»ç¯å¢ƒå˜é‡è¯»å– GitHub Token
import os
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")
if not GITHUB_TOKEN:
    raise EnvironmentError("GITHUB_TOKEN ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·åœ¨ ~/.openclaw/.env ä¸­é…ç½®")
OUTPUT_DIR = Path("/home/writer/.openclaw/workspace/logs/community-scraper")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def github_api(endpoint):
    """GitHub API è¯·æ±‚"""
    url = f"https://api.github.com/{endpoint}"
    req = urllib.request.Request(url)
    req.add_header('Authorization', f'token {GITHUB_TOKEN}')
    req.add_header('Accept', 'application/vnd.github.v3+json')
    
    ctx = ssl.create_default_context()
    try:
        response = urllib.request.urlopen(req, context=ctx, timeout=15)
        return json.load(response)
    except Exception as e:
        print(f"âŒ API è¯·æ±‚å¤±è´¥ï¼š{e}")
        return None

def fetch_awesome_openclaw():
    """æŠ“å– awesome-openclaw èµ„æºåˆ—è¡¨"""
    print("  ğŸ“š æŠ“å– awesome-openclaw...")
    
    # è·å– README å†…å®¹
    data = github_api("repos/SamurAIGPT/awesome-openclaw/readme")
    if not data:
        return None
    
    # è§£ç  README
    import base64
    content = base64.b64decode(data['content']).decode('utf-8')
    
    # è§£æèµ„æºåˆ†ç±»
    categories = {}
    current_category = None
    
    for line in content.split('\n'):
        if line.startswith('## '):
            current_category = line.replace('## ', '').strip()
            categories[current_category] = []
        elif line.startswith('- [') and current_category:
            # æå–èµ„æºé“¾æ¥
            try:
                title_start = line.find('[') + 1
                title_end = line.find(']')
                url_start = line.find('(') + 1
                url_end = line.find(')')
                
                if title_end > title_start and url_end > url_start:
                    title = line[title_start:title_end]
                    url = line[url_start:url_end]
                    categories[current_category].append({
                        "title": title,
                        "url": url
                    })
            except:
                pass
    
    return {
        "categories": categories,
        "total_resources": sum(len(v) for v in categories.values()),
        "category_count": len(categories)
    }

def fetch_clawhub_skills():
    """æŠ“å– ClawHub æŠ€èƒ½ç»Ÿè®¡"""
    print("  ğŸ› ï¸  æŠ“å– ClawHub æŠ€èƒ½...")
    
    # ClawHub æ²¡æœ‰å…¬å¼€ APIï¼Œé€šè¿‡ GitHub skills ä»“åº“ä¼°ç®—
    data = github_api("repos/openclaw/skills")
    if not data:
        return None
    
    return {
        "stars": data.get('stargazers_count', 0),
        "forks": data.get('forks_count', 0),
        "url": data.get('html_url', ''),
        "description": data.get('description', '')
    }

def fetch_hacker_news_ai():
    """æŠ“å– Hacker News AI ç›¸å…³è®¨è®º"""
    print("  ğŸ“° æŠ“å– Hacker News...")
    
    # é‡è¯•æœºåˆ¶å‡½æ•°
    def fetch_with_retry(url, timeout=10, max_retries=3):
        for attempt in range(max_retries):
            try:
                ctx = ssl.create_default_context()
                response = urllib.request.urlopen(url, context=ctx, timeout=timeout)
                return json.load(response)
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"    âš ï¸  é‡è¯• {attempt + 1}/{max_retries}...")
                    import time
                    time.sleep(1)
                else:
                    raise e
        return None
    
    # Hacker News API
    try:
        # è·å–çƒ­é—¨æ•…äº‹ï¼ˆå¸¦é‡è¯•ï¼‰
        top_stories_url = "https://hacker-news.firebaseio.com/v0/topstories.json"
        top_ids = fetch_with_retry(top_stories_url, timeout=10)[:50]  # å‰ 50 ä¸ª
        
        # è·å–æ•…äº‹è¯¦æƒ…å¹¶è¿‡æ»¤ AI ç›¸å…³
        ai_stories = []
        for story_id in top_ids[:20]:  # æ£€æŸ¥å‰ 20 ä¸ª
            story_url = f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
            try:
                story = fetch_with_retry(story_url, timeout=5)
                
                # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ…å« AI å…³é”®è¯
                title = story.get('title', '').lower()
                if any(kw in title for kw in ['ai', 'agent', 'openclaw', 'llm', 'gpt', 'claude']):
                    ai_stories.append({
                        "title": story.get('title', ''),
                        "url": story.get('url', ''),
                        "score": story.get('score', 0),
                        "comments": story.get('descendants', 0),
                        "hn_url": f"https://news.ycombinator.com/item?id={story_id}"
                    })
            except:
                pass
        
        return ai_stories
    except Exception as e:
        print(f"    âš ï¸  HN æŠ“å–å¤±è´¥ï¼š{e}")
        return []

def generate_community_report():
    """ç”Ÿæˆç¤¾åŒºè¶‹åŠ¿æŠ¥å‘Š"""
    print("ğŸ” å¼€å§‹ç¤¾åŒºå†…å®¹æŠ“å–...")
    
    report = {
        "generated_at": datetime.now().isoformat(),
        "sources": {}
    }
    
    # awesome-openclaw
    awesome_data = fetch_awesome_openclaw()
    if awesome_data:
        report["sources"]["awesome-openclaw"] = awesome_data
    
    # ClawHub
    clawhub_data = fetch_clawhub_skills()
    if clawhub_data:
        report["sources"]["clawhub"] = clawhub_data
    
    # Hacker News
    hn_stories = fetch_hacker_news_ai()
    if hn_stories:
        report["sources"]["hacker-news"] = {
            "ai_stories": hn_stories,
            "count": len(hn_stories)
        }
    
    # ç”Ÿæˆç¤¾åŒºæ´å¯Ÿ
    print("  ğŸ’¡ ç”Ÿæˆç¤¾åŒºæ´å¯Ÿ...")
    insights = []
    
    # æ´å¯Ÿ 1: ç”Ÿæ€ç³»ç»Ÿè§„æ¨¡
    if awesome_data and clawhub_data:
        insights.append({
            "type": "ecosystem",
            "title": "OpenClaw ç”Ÿæ€ç³»ç»ŸæŒç»­æ‰©å¼ ",
            "details": [
                f"awesome-openclaw: {awesome_data['total_resources']} ä¸ªèµ„æºï¼Œ{awesome_data['category_count']} ä¸ªåˆ†ç±»",
                f"ClawHub: {clawhub_data['stars']} stars, {clawhub_data['forks']} forks"
            ]
        })
    
    # æ´å¯Ÿ 2: ç¤¾åŒºçƒ­ç‚¹
    if hn_stories:
        insights.append({
            "type": "trending",
            "title": f"Hacker News å‘ç° {len(hn_stories)} ä¸ª AI ç›¸å…³è®¨è®º",
            "stories": hn_stories[:5]
        })
    
    report["insights"] = insights
    
    # ä¿å­˜æŠ¥å‘Š
    output_file = OUTPUT_DIR / f"community-scraper-{datetime.now().strftime('%Y%m%d')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜ï¼š{output_file}")
    
    # ç”Ÿæˆ Markdown æ‘˜è¦
    md_summary = generate_markdown_summary(report)
    md_file = OUTPUT_DIR / f"community-scraper-{datetime.now().strftime('%Y%m%d')}.md"
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(md_summary)
    
    print(f"âœ… Markdown æ‘˜è¦å·²ä¿å­˜ï¼š{md_file}")
    
    return report

def generate_markdown_summary(report):
    """ç”Ÿæˆ Markdown æ‘˜è¦"""
    md = ["# ç¤¾åŒºè¶‹åŠ¿æ—¥æŠ¥", ""]
    md.append(f"**ç”Ÿæˆæ—¶é—´**: {report['generated_at'][:19]}")
    md.append("")
    
    # awesome-openclaw
    if "awesome-openclaw" in report["sources"]:
        awesome = report["sources"]["awesome-openclaw"]
        md.append("## ğŸ“š awesome-openclaw")
        md.append("")
        md.append(f"- ğŸ“¦ èµ„æºæ€»æ•°ï¼š**{awesome['total_resources']}**")
        md.append(f"- ğŸ“‚ åˆ†ç±»æ•°é‡ï¼š**{awesome['category_count']}**")
        md.append("")
        
        md.append("### ä¸»è¦åˆ†ç±»")
        for cat, resources in list(awesome['categories'].items())[:5]:
            md.append(f"- **{cat}**: {len(resources)} ä¸ªèµ„æº")
        md.append("")
    
    # ClawHub
    if "clawhub" in report["sources"]:
        clawhub = report["sources"]["clawhub"]
        md.append("## ğŸ› ï¸  ClawHub æŠ€èƒ½")
        md.append("")
        md.append(f"- â­ Stars: {clawhub['stars']}")
        md.append(f"- ğŸ´ Forks: {clawhub['forks']}")
        md.append(f"- ğŸ“„ {clawhub['description']}")
        md.append("")
    
    # Hacker News
    if "hacker-news" in report["sources"]:
        hn = report["sources"]["hacker-news"]
        md.append("## ğŸ“° Hacker News AI è®¨è®º")
        md.append("")
        md.append(f"å‘ç° **{hn['count']}** ä¸ª AI ç›¸å…³è®¨è®º")
        md.append("")
        
        for i, story in enumerate(hn['ai_stories'][:5], 1):
            md.append(f"{i}. [{story['title']}]({story['hn_url']})")
            md.append(f"   - ğŸ‘ {story['score']} åˆ† | ğŸ’¬ {story['comments']} è¯„è®º")
        md.append("")
    
    # ç¤¾åŒºæ´å¯Ÿ
    if report["insights"]:
        md.append("## ğŸ’¡ ç¤¾åŒºæ´å¯Ÿ")
        md.append("")
        
        for insight in report["insights"]:
            md.append(f"### {insight['title']}")
            if insight['type'] == 'ecosystem':
                for detail in insight['details']:
                    md.append(f"- {detail}")
            elif insight['type'] == 'trending':
                for story in insight['stories']:
                    md.append(f"- {story['title']}")
            md.append("")
    
    md.append("---")
    md.append("*è‡ªåŠ¨ç”Ÿæˆäº Community Scraper*")
    
    return '\n'.join(md)

if __name__ == "__main__":
    report = generate_community_report()
    print("\nğŸ“Š ç¤¾åŒºæŠ“å–å®Œæˆï¼")
    print(f"  - å‘ç° {len(report['insights'])} æ¡ç¤¾åŒºæ´å¯Ÿ")
    if "awesome-openclaw" in report["sources"]:
        print(f"  - awesome-openclaw: {report['sources']['awesome-openclaw']['total_resources']} ä¸ªèµ„æº")
    if "hacker-news" in report["sources"]:
        print(f"  - Hacker News: {report['sources']['hacker-news']['count']} ä¸ª AI è®¨è®º")
