#!/usr/bin/env python3
"""
æ¯å‘¨å¤ç›˜åˆ†æå™¨ v3.0
åŠŸèƒ½ï¼š
  1. åŠ è½½ä¸Šå‘¨å…¨éƒ¨æ—¥æŠ¥
  2. èšåˆåˆ†æ + è¶‹åŠ¿è¯†åˆ«
  3. è¡ŒåŠ¨é¡¹å®Œæˆæ£€æŸ¥
  4. LLM ç”Ÿæˆæ”¹è¿›è¡ŒåŠ¨åˆ—è¡¨
  5. Notion å‘¨æŠ¥é¡µé¢
  6. Telegram æ¨é€
"""

import json
import os
import ssl
import sys
import urllib.request
from datetime import datetime, timedelta
from pathlib import Path

# === è·¯å¾„é…ç½® ===
WORKSPACE_DIR = Path("/home/writer/.openclaw/workspace")
LOGS_DIR = WORKSPACE_DIR / "logs"
SKILL_DIR = WORKSPACE_DIR / "skills" / "learning-upgrade"
TRACKER_DIR = SKILL_DIR / "tracker"
OUTPUT_DIR = LOGS_DIR / "weekly-review"

# === API é…ç½® ===
ARK_API_KEY = os.environ.get('ARK_API_KEY', '')
ARK_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
MATON_API_KEY = os.environ.get('MATON_API_KEY', '')
MATON_BASE_URL = "https://gateway.maton.ai/v1"

# Notion æ ¹é¡µé¢ ID
LEARNING_DIARY_ROOT_ID = "1a09bfd6-0b4f-80d7-ab33-ca2e38e0d9f0"

# === å·¥å…·å‡½æ•° ===

def load_env():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    env_file = Path("/home/writer/.openclaw/.env")
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    # å¤„ç† export KEY=VALUE å’Œ KEY=VALUE ä¸¤ç§æ ¼å¼
                    if line.startswith('export '):
                        line = line[7:]
                    key, _, value = line.partition('=')
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    os.environ[key] = value

    global ARK_API_KEY, MATON_API_KEY
    ARK_API_KEY = os.environ.get('ARK_API_KEY', ARK_API_KEY)
    MATON_API_KEY = os.environ.get('MATON_API_KEY', MATON_API_KEY)


def get_last_week_range():
    """è·å–ä¸Šå‘¨çš„æ—¥æœŸèŒƒå›´ (å‘¨ä¸€~å‘¨æ—¥)"""
    today = datetime.now()
    # æ‰¾åˆ°æœ¬å‘¨ä¸€
    this_monday = today - timedelta(days=today.weekday())
    # ä¸Šå‘¨ä¸€ ~ ä¸Šå‘¨æ—¥
    last_monday = this_monday - timedelta(days=7)
    last_sunday = this_monday - timedelta(days=1)
    return last_monday, last_sunday


def get_week_number(date):
    """è·å– ISO å‘¨æ•°"""
    return f"{date.year}-W{date.isocalendar()[1]:02d}"


def load_daily_reports(start_date, end_date):
    """åŠ è½½æ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æ—¥æŠ¥"""
    reports = []
    current = start_date

    while current <= end_date:
        date_stamp = current.strftime('%Y%m%d')
        date_str = current.strftime('%Y-%m-%d')

        daily = {"date": date_str, "sources": {}}

        # GitHub æŠ¥å‘Š
        gh_file = LOGS_DIR / "github-monitor" / f"github-monitor-{date_stamp}.md"
        if gh_file.exists():
            with open(gh_file, 'r', encoding='utf-8') as f:
                daily["sources"]["github"] = f.read()

        # ç¤¾åŒºæŠ¥å‘Š
        comm_file = LOGS_DIR / "community-scraper" / f"community-scraper-{date_stamp}.md"
        if comm_file.exists():
            with open(comm_file, 'r', encoding='utf-8') as f:
                daily["sources"]["community"] = f.read()

        # æŠ€æœ¯åˆ†æ
        tech_file = LOGS_DIR / "tech-analyzer" / f"tech-analysis-{date_stamp}.md"
        if tech_file.exists():
            with open(tech_file, 'r', encoding='utf-8') as f:
                daily["sources"]["tech"] = f.read()

        # æŠ€æœ¯åˆ†æ JSONï¼ˆå¦‚æœæœ‰ï¼‰
        tech_json = LOGS_DIR / "tech-analyzer" / f"tech-analysis-{date_stamp}.json"
        if tech_json.exists():
            with open(tech_json, 'r', encoding='utf-8') as f:
                try:
                    daily["sources"]["tech_json"] = json.load(f)
                except json.JSONDecodeError:
                    pass

        if daily["sources"]:
            reports.append(daily)

        current += timedelta(days=1)

    return reports


def load_action_items(week_id):
    """åŠ è½½æŸå‘¨çš„è¡ŒåŠ¨é¡¹"""
    # å¯¼å…¥ action-tracker
    sys.path.insert(0, str(SKILL_DIR / "tools"))
    try:
        import importlib
        at = importlib.import_module("action-tracker")
        return at.check_items_by_week(week_id)
    except Exception as e:
        print(f"  âš ï¸ æ— æ³•åŠ è½½ action-tracker: {e}")
        # ç›´æ¥è¯» JSON æ–‡ä»¶
        action_file = TRACKER_DIR / "action-items.json"
        if action_file.exists():
            with open(action_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            items = [i for i in data.get("items", []) if i.get("review_week") == week_id]
            return {
                "week": week_id,
                "items": items,
                "total": len(items),
                "done": sum(1 for i in items if i["status"] == "done"),
                "pending": sum(1 for i in items if i["status"] == "pending"),
                "completion_rate": round(
                    sum(1 for i in items if i["status"] == "done") / max(len(items), 1), 2
                )
            }
        return {"week": week_id, "items": [], "total": 0, "done": 0, "pending": 0, "completion_rate": 0}


def aggregate_analysis(reports):
    """èšåˆåˆ†æ - æå–å…³é”®ä¿¡æ¯"""

    all_text = ""
    tech_highlights = []
    github_events = []
    community_insights = []

    for report in reports:
        for source_type, content in report["sources"].items():
            if isinstance(content, str):
                all_text += f"\n--- {report['date']} {source_type} ---\n{content}\n"
            elif isinstance(content, dict) and source_type == "tech_json":
                # ä» JSON æå–ç»“æ„åŒ–æ•°æ®
                for highlight in content.get("architecture_highlights", []):
                    tech_highlights.append({
                        "date": report["date"],
                        "title": highlight.get("title", ""),
                        "impact": highlight.get("impact", "")
                    })

    return {
        "daily_count": len(reports),
        "dates": [r["date"] for r in reports],
        "combined_text": all_text[:15000],  # é™åˆ¶é•¿åº¦
        "tech_highlights": tech_highlights,
        "missing_days": 7 - len(reports)
    }


def llm_weekly_analysis(aggregated_data, action_items_result):
    """è°ƒç”¨ LLM è¿›è¡Œå‘¨åº¦ç»¼åˆåˆ†æ"""

    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±æŠ€æœ¯å­¦ä¹ é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹ä¸€å‘¨çš„æŠ€æœ¯å­¦ä¹ å†…å®¹è¿›è¡Œç»¼åˆåˆ†æã€‚

## æœ¬å‘¨å­¦ä¹ æ•°æ®

å­¦ä¹ å¤©æ•°: {aggregated_data['daily_count']}/7
è¦†ç›–æ—¥æœŸ: {', '.join(aggregated_data['dates'])}
ç¼ºå¤±å¤©æ•°: {aggregated_data['missing_days']}

## æœ¬å‘¨è¡ŒåŠ¨é¡¹æƒ…å†µ

æ€»è®¡: {action_items_result['total']} é¡¹
å·²å®Œæˆ: {action_items_result['done']} é¡¹
å®Œæˆç‡: {action_items_result['completion_rate'] * 100:.0f}%

## æœ¬å‘¨å­¦ä¹ å†…å®¹æ‘˜è¦

{aggregated_data['combined_text'][:8000]}

## è¯·è¾“å‡ºä»¥ä¸‹åˆ†æ (JSON æ ¼å¼):

```json
{{
  "tech_top5": [
    {{"topic": "è¯é¢˜åç§°", "frequency": å‡ºç°æ¬¡æ•°, "importance": "é«˜/ä¸­/ä½"}}
  ],
  "key_events": [
    {{"event": "äº‹ä»¶æè¿°", "date": "æ—¥æœŸ", "significance": "é‡è¦æ€§è¯´æ˜"}}
  ],
  "knowledge_gained": [
    {{"knowledge": "å­¦åˆ°çš„çŸ¥è¯†ç‚¹", "depth": "æµ…/ä¸­/æ·±", "applicable": true/false}}
  ],
  "trends": [
    {{"trend": "è¶‹åŠ¿åç§°", "direction": "ä¸Šå‡/ä¸‹é™/æŒå¹³", "evidence": "è¯æ®"}}
  ],
  "improvement_actions": [
    {{
      "title": "æ”¹è¿›æ–¹å‘",
      "priority": "high/medium/low",
      "expected_benefit": "é¢„æœŸæ”¶ç›Š",
      "steps": ["æ­¥éª¤1", "æ­¥éª¤2", "æ­¥éª¤3"],
      "expected_days": 7,
      "why_makes_stronger": "ä¸ºä»€ä¹ˆè¿™ä¸ªæ”¹è¿›èƒ½è®©ä½ å˜å¾—æ›´å¼º"
    }}
  ]
}}
```

æ”¹è¿›å»ºè®®è¦æ±‚:
1. æœ€å¤š 5 é¡¹ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
2. æ¯é¡¹å¿…é¡»æœ‰å…·ä½“å¯æ‰§è¡Œçš„æ­¥éª¤
3. é‡ç‚¹è¯†åˆ«èƒ½è®©äººå˜å¾—æ›´å¼ºçš„é«˜ä»·å€¼æ”¹è¿›æ–¹å‘
4. ä¸è¦æ³›æ³›è€Œè°ˆï¼Œè¦é’ˆå¯¹æœ¬å‘¨å…·ä½“å†…å®¹
"""

    url = f"{ARK_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {ARK_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "glm-4.7",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æŠ€æœ¯å­¦ä¹ é¡¾é—®ï¼Œæ“…é•¿ä»å­¦ä¹ å†…å®¹ä¸­æç‚¼é«˜ä»·å€¼æ´å¯Ÿå’Œæ”¹è¿›å»ºè®®ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 4000
    }

    ctx = ssl.create_default_context()
    try:
        req = urllib.request.Request(
            url,
            data=json.dumps(payload).encode('utf-8'),
            headers=headers,
            method='POST'
        )
        response = urllib.request.urlopen(req, context=ctx, timeout=180)
        result = json.load(response)
        content = result['choices'][0]['message']['content']

        # è§£æ JSON
        import re
        json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        else:
            return json.loads(content)
    except Exception as e:
        print(f"âŒ LLM åˆ†æå¤±è´¥: {e}")
        return None


def generate_weekly_report(week_id, date_range, aggregated, action_items, llm_analysis):
    """ç”Ÿæˆ Markdown æ ¼å¼å‘¨æŠ¥"""
    start_str = date_range[0].strftime('%m/%d')
    end_str = date_range[1].strftime('%m/%d')
    week_num = date_range[0].isocalendar()[1]

    md = []
    md.append(f"# ğŸ“Š ç¬¬ {week_num:02d} å‘¨ å‘¨æŠ¥ ({start_str} - {end_str})")
    md.append("")
    md.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    md.append("")

    # æœ¬å‘¨æ¦‚è§ˆ
    md.append("## æœ¬å‘¨æ¦‚è§ˆ")
    md.append(f"- å­¦ä¹ å¤©æ•°: {aggregated['daily_count']}/7")
    md.append(f"- è¡ŒåŠ¨é¡¹å®Œæˆç‡: {action_items['completion_rate'] * 100:.0f}%")
    if llm_analysis:
        md.append(f"- æ–°å‘ç°æŠ€æœ¯: {len(llm_analysis.get('knowledge_gained', []))} é¡¹")
    md.append("")

    if llm_analysis:
        # æŠ€æœ¯çƒ­åº¦ TOP 5
        if llm_analysis.get("tech_top5"):
            md.append("## ğŸ”¥ æŠ€æœ¯çƒ­åº¦ TOP 5")
            md.append("")
            for i, topic in enumerate(llm_analysis["tech_top5"][:5], 1):
                md.append(f"{i}. **{topic['topic']}** â€” é‡è¦æ€§: {topic['importance']}")
            md.append("")

        # å…³é”®äº‹ä»¶
        if llm_analysis.get("key_events"):
            md.append("## ğŸ“° å…³é”®äº‹ä»¶")
            md.append("")
            for event in llm_analysis["key_events"]:
                md.append(f"- [{event.get('date', '')}] {event['event']}")
            md.append("")

        # æœ¬å‘¨çŸ¥è¯†æ”¶è·
        if llm_analysis.get("knowledge_gained"):
            md.append("## ğŸ§  æœ¬å‘¨çŸ¥è¯†æ”¶è·")
            md.append("")
            for k in llm_analysis["knowledge_gained"]:
                applicable = "âœ… å¯åº”ç”¨" if k.get("applicable") else "ğŸ“– å¾…æ·±å…¥"
                md.append(f"- {k['knowledge']} (æ·±åº¦: {k['depth']}) â€” {applicable}")
            md.append("")

    # è¡ŒåŠ¨é¡¹æ£€æŸ¥
    md.append("## âœ… è¡ŒåŠ¨é¡¹æ£€æŸ¥")
    md.append("")
    if action_items["items"]:
        md.append("| è¡ŒåŠ¨é¡¹ | ä¼˜å…ˆçº§ | çŠ¶æ€ | é¢„æœŸå®Œæˆ |")
        md.append("|--------|--------|------|---------|")
        status_emoji = {"pending": "â³", "in_progress": "ğŸ”„", "done": "âœ…", "dropped": "ğŸ—‘ï¸"}
        for item in action_items["items"]:
            emoji = status_emoji.get(item["status"], "â“")
            md.append(f"| {item['title'][:40]} | {item['priority']} | {emoji} {item['status']} | {item.get('expected_by', '-')} |")
        md.append("")
        md.append(f"**å®Œæˆç‡**: {action_items['completion_rate'] * 100:.0f}% ({action_items['done']}/{action_items['total']})")
    else:
        md.append("æœ¬å‘¨æš‚æ— è¡ŒåŠ¨é¡¹è®°å½•")
    md.append("")

    # æ”¹è¿›è¡ŒåŠ¨åˆ—è¡¨
    if llm_analysis and llm_analysis.get("improvement_actions"):
        md.append("## ğŸš€ æ”¹è¿›è¡ŒåŠ¨åˆ—è¡¨")
        md.append("")
        for i, action in enumerate(llm_analysis["improvement_actions"][:5], 1):
            priority_map = {"high": "ğŸ”´ é«˜", "medium": "ğŸŸ¡ ä¸­", "low": "ğŸŸ¢ ä½"}
            priority_label = priority_map.get(action.get("priority", "medium"), "ğŸŸ¡ ä¸­")
            md.append(f"### {i}. {action['title']} [{priority_label}]")
            md.append(f"**é¢„æœŸæ”¶ç›Š**: {action.get('expected_benefit', 'æœªçŸ¥')}")
            md.append(f"**ä¸ºä»€ä¹ˆèƒ½å˜å¼º**: {action.get('why_makes_stronger', 'æœªçŸ¥')}")
            md.append("")
            if action.get("steps"):
                md.append("**å…·ä½“æ­¥éª¤**:")
                for step in action["steps"]:
                    md.append(f"  - [ ] {step}")
            md.append("")

    # è¶‹åŠ¿æ´å¯Ÿ
    if llm_analysis and llm_analysis.get("trends"):
        md.append("## ğŸ“ˆ è¶‹åŠ¿æ´å¯Ÿ")
        md.append("")
        for trend in llm_analysis["trends"]:
            direction_emoji = {"ä¸Šå‡": "ğŸ“ˆ", "ä¸‹é™": "ğŸ“‰", "æŒå¹³": "â¡ï¸"}
            emoji = direction_emoji.get(trend.get("direction", ""), "â“")
            md.append(f"- {emoji} **{trend['trend']}** ({trend['direction']})")
            md.append(f"  - è¯æ®: {trend.get('evidence', 'æ— ')}")
        md.append("")

    md.append("---")
    md.append("*è‡ªåŠ¨ç”Ÿæˆäº Weekly Reviewer v3.0*")

    return '\n'.join(md)


def notion_request(endpoint, method='GET', data=None):
    """Notion API è¯·æ±‚ (é€šè¿‡ Maton Gateway)"""
    url = f"{MATON_BASE_URL}/notion/{endpoint}"
    headers = {
        "Authorization": f"Bearer {MATON_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }

    ctx = ssl.create_default_context()
    try:
        req_data = json.dumps(data).encode('utf-8') if data else None
        req = urllib.request.Request(url, data=req_data, headers=headers, method=method)
        response = urllib.request.urlopen(req, context=ctx, timeout=30)
        return json.load(response)
    except Exception as e:
        print(f"âŒ Notion è¯·æ±‚å¤±è´¥: {e}")
        return None


def search_notion_page(title):
    """æœç´¢ Notion é¡µé¢"""
    result = notion_request("search", method='POST', data={
        "query": title,
        "filter": {"property": "object", "value": "page"}
    })
    if result and result.get("results"):
        for page in result["results"]:
            page_title = ""
            props = page.get("properties", {})
            if "title" in props:
                title_arr = props["title"].get("title", [])
                if title_arr:
                    page_title = title_arr[0].get("plain_text", "")
            if title in page_title:
                return page.get("id")
    return None


def create_weekly_notion_page(week_num, start_str, end_str, month_page_id, report_content):
    """åœ¨ Notion åˆ›å»ºå‘¨æŠ¥é¡µé¢"""

    # å°† markdown å†…å®¹è½¬ä¸º Notion blocks
    children = []

    # æ ‡é¢˜
    children.append({
        "object": "block",
        "type": "heading_2",
        "heading_2": {
            "rich_text": [{"type": "text", "text": {"content": f"ğŸ“Š ç¬¬ {week_num:02d} å‘¨ å‘¨æŠ¥ ({start_str} - {end_str})"}}]
        }
    })

    # å…ƒæ•°æ®
    children.append({
        "object": "block",
        "type": "callout",
        "callout": {
            "rich_text": [{"type": "text", "text": {"content": f"ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}"}}],
            "icon": {"emoji": "ğŸ“Š"}
        }
    })

    # æŠ¥å‘Šå†…å®¹æŒ‰æ®µè½æ·»åŠ 
    for line in report_content.split('\n'):
        line = line.strip()
        if not line:
            continue
        if line.startswith('# '):
            continue  # è·³è¿‡é¡¶çº§æ ‡é¢˜
        elif line.startswith('## '):
            children.append({
                "object": "block",
                "type": "heading_3",
                "heading_3": {
                    "rich_text": [{"type": "text", "text": {"content": line[3:]}}]
                }
            })
        elif line.startswith('### '):
            children.append({
                "object": "block",
                "type": "heading_3",
                "heading_3": {
                    "rich_text": [{"type": "text", "text": {"content": line[4:]}}]
                }
            })
        elif line.startswith('- [ ] '):
            children.append({
                "object": "block",
                "type": "to_do",
                "to_do": {
                    "rich_text": [{"type": "text", "text": {"content": line[6:]}}],
                    "checked": False
                }
            })
        elif line.startswith('- [x] '):
            children.append({
                "object": "block",
                "type": "to_do",
                "to_do": {
                    "rich_text": [{"type": "text", "text": {"content": line[6:]}}],
                    "checked": True
                }
            })
        elif line.startswith('- '):
            children.append({
                "object": "block",
                "type": "bulleted_list_item",
                "bulleted_list_item": {
                    "rich_text": [{"type": "text", "text": {"content": line[2:][:2000]}}]
                }
            })
        elif line.startswith('|') and '---' not in line:
            # è¡¨æ ¼è¡Œ â†’ è½¬ä¸ºæ–‡æœ¬
            children.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": line[:2000]}}]
                }
            })
        elif line.startswith('**') and line.endswith('**'):
            children.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": line[:2000]}}]
                }
            })
        elif line == '---':
            children.append({
                "object": "block",
                "type": "divider",
                "divider": {}
            })
        elif len(line) > 2:
            children.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": line[:2000]}}]
                }
            })

    # é™åˆ¶ blocks æ•°é‡ï¼ˆNotion API é™åˆ¶ 100ï¼‰
    children = children[:95]

    page_title = f"ğŸ“Š ç¬¬ {week_num:02d} å‘¨ å‘¨æŠ¥ ({start_str}-{end_str})"

    page_data = {
        "parent": {"page_id": month_page_id},
        "properties": {
            "title": [{"type": "text", "text": {"content": page_title}}]
        },
        "children": children
    }

    result = notion_request("pages", method='POST', data=page_data)
    return result


def save_improvement_actions(llm_analysis, week_id):
    """å°†æ”¹è¿›è¡ŒåŠ¨é¡¹ä¿å­˜åˆ° tracker"""
    if not llm_analysis or not llm_analysis.get("improvement_actions"):
        return

    sys.path.insert(0, str(SKILL_DIR / "tools"))
    try:
        import importlib
        at = importlib.import_module("action-tracker")

        for action in llm_analysis["improvement_actions"][:5]:
            at.add_item(
                title=action["title"],
                priority=action.get("priority", "medium"),
                source="weekly",
                steps=action.get("steps", []),
                expected_days=action.get("expected_days", 7)
            )
        print(f"âœ… å·²ä¿å­˜ {min(len(llm_analysis['improvement_actions']), 5)} ä¸ªæ”¹è¿›è¡ŒåŠ¨é¡¹")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜è¡ŒåŠ¨é¡¹å¤±è´¥: {e}")


# === ä¸»æµç¨‹ ===

def main():
    print("=" * 60)
    print("ğŸ“Š Learning Upgrade â€” æ¯å‘¨å¤ç›˜åˆ†æå™¨ v3.0")
    print("=" * 60)

    # åŠ è½½ç¯å¢ƒå˜é‡
    load_env()

    # è·å–ä¸Šå‘¨æ—¥æœŸèŒƒå›´
    last_monday, last_sunday = get_last_week_range()
    week_id = get_week_number(last_monday)
    start_str = last_monday.strftime('%m/%d')
    end_str = last_sunday.strftime('%m/%d')
    week_num = last_monday.isocalendar()[1]

    print(f"\nğŸ“… å¤ç›˜èŒƒå›´: {last_monday.strftime('%Y-%m-%d')} ~ {last_sunday.strftime('%Y-%m-%d')} ({week_id})")

    # Step 1: åŠ è½½æ—¥æŠ¥
    print(f"\nğŸ“¥ æ­¥éª¤ 1/6: åŠ è½½ä¸Šå‘¨æ—¥æŠ¥...")
    reports = load_daily_reports(last_monday, last_sunday)
    print(f"  âœ… åŠ è½½ {len(reports)}/7 å¤©æ—¥æŠ¥")

    if not reports:
        print("  âŒ æœªæ‰¾åˆ°ä»»ä½•æ—¥æŠ¥æ•°æ®ï¼Œè·³è¿‡æœ¬å‘¨å¤ç›˜")
        return

    # Step 2: èšåˆåˆ†æ
    print(f"\nğŸ“Š æ­¥éª¤ 2/6: èšåˆåˆ†æ...")
    aggregated = aggregate_analysis(reports)
    print(f"  âœ… èšåˆå®Œæˆï¼ˆ{aggregated['daily_count']} å¤©ï¼Œç¼ºå¤± {aggregated['missing_days']} å¤©ï¼‰")

    # Step 3: è¡ŒåŠ¨é¡¹æ£€æŸ¥
    print(f"\nâœ… æ­¥éª¤ 3/6: è¡ŒåŠ¨é¡¹å®Œæˆæ£€æŸ¥...")
    action_items = load_action_items(week_id)
    print(f"  æ€»è®¡: {action_items['total']}  å®Œæˆ: {action_items['done']}  å®Œæˆç‡: {action_items['completion_rate'] * 100:.0f}%")

    # Step 4: LLM åˆ†æ
    print(f"\nğŸ¤– æ­¥éª¤ 4/6: LLM æ·±åº¦åˆ†æ...")
    llm_analysis = llm_weekly_analysis(aggregated, action_items)
    if llm_analysis:
        print(f"  âœ… åˆ†æå®Œæˆ")
        print(f"    - æŠ€æœ¯çƒ­åº¦: {len(llm_analysis.get('tech_top5', []))} é¡¹")
        print(f"    - å…³é”®äº‹ä»¶: {len(llm_analysis.get('key_events', []))} ä¸ª")
        print(f"    - çŸ¥è¯†æ”¶è·: {len(llm_analysis.get('knowledge_gained', []))} ç‚¹")
        print(f"    - æ”¹è¿›å»ºè®®: {len(llm_analysis.get('improvement_actions', []))} é¡¹")

        # ä¿å­˜æ”¹è¿›è¡ŒåŠ¨é¡¹åˆ° tracker
        save_improvement_actions(llm_analysis, week_id)
    else:
        print("  âš ï¸ LLM åˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ•°æ®ç”ŸæˆæŠ¥å‘Š")

    # Step 5: ç”ŸæˆæŠ¥å‘Š & Notion
    print(f"\nğŸ“ æ­¥éª¤ 5/6: ç”Ÿæˆå‘¨æŠ¥ & Notion æ›´æ–°...")

    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    report_md = generate_weekly_report(
        week_id, (last_monday, last_sunday),
        aggregated, action_items, llm_analysis
    )

    # ä¿å­˜æœ¬åœ°æ–‡ä»¶
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    report_file = OUTPUT_DIR / f"{week_id}.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_md)
    print(f"  âœ… æœ¬åœ°æŠ¥å‘Š: {report_file}")

    # ä¿å­˜ JSON åˆ†æç»“æœ
    if llm_analysis:
        json_file = OUTPUT_DIR / f"{week_id}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(llm_analysis, f, ensure_ascii=False, indent=2)

    # Notion å‘¨æŠ¥
    year_month = last_monday.strftime('%Y å¹´ %m æœˆ')
    print(f"  ğŸ” æœç´¢ {year_month} é¡µé¢...")
    month_page_id = search_notion_page(year_month)

    if month_page_id:
        print(f"  âœ… å‘ç°æœˆä»½é¡µé¢: {month_page_id}")

        # æ£€æŸ¥å‘¨æŠ¥é¡µé¢æ˜¯å¦å·²å­˜åœ¨
        weekly_title = f"ç¬¬ {week_num:02d} å‘¨"
        existing = search_notion_page(weekly_title)
        if existing:
            print(f"  âš ï¸ å‘¨æŠ¥é¡µé¢å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
        else:
            result = create_weekly_notion_page(
                week_num, start_str, end_str,
                month_page_id, report_md
            )
            if result:
                page_id = result.get('id', '')
                print(f"  âœ… Notion å‘¨æŠ¥åˆ›å»ºæˆåŠŸ: {page_id}")
            else:
                print(f"  âŒ Notion å‘¨æŠ¥åˆ›å»ºå¤±è´¥")
    else:
        print(f"  âš ï¸ æœªæ‰¾åˆ° {year_month} é¡µé¢ï¼Œè·³è¿‡ Notion æ›´æ–°")

    # Step 6: ç”Ÿæˆ Telegram æ‘˜è¦
    print(f"\nğŸ“± æ­¥éª¤ 6/6: ç”Ÿæˆ Telegram æ‘˜è¦...")
    tg_summary = generate_telegram_summary(
        week_id, week_num, start_str, end_str,
        aggregated, action_items, llm_analysis
    )
    print(tg_summary)

    print(f"\n{'=' * 60}")
    print(f"ğŸ‰ æ¯å‘¨å¤ç›˜å®Œæˆï¼({week_id})")
    print(f"{'=' * 60}")


def generate_telegram_summary(week_id, week_num, start_str, end_str, aggregated, action_items, llm_analysis):
    """ç”Ÿæˆ Telegram æ¨é€æ‘˜è¦"""
    lines = []
    lines.append(f"ğŸ“Š ç¬¬ {week_num:02d} å‘¨ å¤ç›˜å®Œæˆ ({start_str}-{end_str})")
    lines.append("")
    lines.append(f"ğŸ“… å­¦ä¹ å¤©æ•°: {aggregated['daily_count']}/7")
    lines.append(f"âœ… è¡ŒåŠ¨é¡¹å®Œæˆç‡: {action_items['completion_rate'] * 100:.0f}%")

    if llm_analysis:
        # TOP 3 æŠ€æœ¯çƒ­åº¦
        top_techs = llm_analysis.get("tech_top5", [])[:3]
        if top_techs:
            lines.append("")
            lines.append("ğŸ”¥ æœ¬å‘¨æŠ€æœ¯çƒ­åº¦:")
            for t in top_techs:
                lines.append(f"  â€¢ {t['topic']}")

        # TOP æ”¹è¿›å»ºè®®
        improvements = llm_analysis.get("improvement_actions", [])[:3]
        if improvements:
            lines.append("")
            lines.append("ğŸš€ é‡ç‚¹æ”¹è¿›:")
            for imp in improvements:
                lines.append(f"  â€¢ {imp['title']}")

    return '\n'.join(lines)


if __name__ == "__main__":
    main()
